{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jihun0423/kaggle_home_credit_default_risk/blob/main/lightgbm_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEHCvFhIvR4F"
      },
      "source": [
        "### Bayesian Optimization을 이용하여 application과 previous로 만들어진 집합의 하이퍼 파라미터 튜닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg1AO0nNvR4H"
      },
      "source": [
        "#### 라이브러리 및 데이터 세트 로딩. 이전 application 데이터의 FE 함수 복사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il0VyvcgvR4K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIJ5-Lu-wbya"
      },
      "source": [
        "##### 코랩 버전은 Google Drive에서 데이터 세트를 로딩"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "VHiS9-DqwUk_",
        "outputId": "e6e77801-773b-4e48-fa9e-59c242c259d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AGuJFDnpnsJDJMhFRp0yQHr1XewIyXdF4Y8Ei6g3QYWxMcTIoSqbxU\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaO4thuSvR4X"
      },
      "outputs": [],
      "source": [
        "def get_dataset():\n",
        "    default_dir = \"/content/gdrive/My Drive\"\n",
        "    app_train = pd.read_csv(os.path.join(default_dir, 'application_train.csv'))\n",
        "    app_test = pd.read_csv(os.path.join(default_dir, 'application_test.csv'))\n",
        "    apps = pd.concat([app_train, app_test])\n",
        "    prev = pd.read_csv(os.path.join(default_dir, 'previous_application.csv'))\n",
        "\n",
        "    return apps, prev\n",
        "\n",
        "apps, prev = get_dataset()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmG4YOdpvR4e"
      },
      "source": [
        "#### 이전 application 데이터의 feature engineering 함수 복사"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WIrIw4uvR4h"
      },
      "outputs": [],
      "source": [
        "def get_apps_processed(apps):\n",
        "\n",
        "    # EXT_SOURCE_X FEATURE 가공\n",
        "    apps['APPS_EXT_SOURCE_MEAN'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis=1)\n",
        "    apps['APPS_EXT_SOURCE_STD'] = apps[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis=1)\n",
        "    apps['APPS_EXT_SOURCE_STD'] = apps['APPS_EXT_SOURCE_STD'].fillna(apps['APPS_EXT_SOURCE_STD'].mean())\n",
        "\n",
        "    # AMT_CREDIT 비율로 Feature 가공\n",
        "    apps['APPS_ANNUITY_CREDIT_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_CREDIT']\n",
        "    apps['APPS_GOODS_CREDIT_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_CREDIT']\n",
        "\n",
        "    # AMT_INCOME_TOTAL 비율로 Feature 가공\n",
        "    apps['APPS_ANNUITY_INCOME_RATIO'] = apps['AMT_ANNUITY']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_CREDIT_INCOME_RATIO'] = apps['AMT_CREDIT']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_GOODS_INCOME_RATIO'] = apps['AMT_GOODS_PRICE']/apps['AMT_INCOME_TOTAL']\n",
        "    apps['APPS_CNT_FAM_INCOME_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['CNT_FAM_MEMBERS']\n",
        "\n",
        "    # DAYS_BIRTH, DAYS_EMPLOYED 비율로 Feature 가공\n",
        "    apps['APPS_EMPLOYED_BIRTH_RATIO'] = apps['DAYS_EMPLOYED']/apps['DAYS_BIRTH']\n",
        "    apps['APPS_INCOME_EMPLOYED_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_EMPLOYED']\n",
        "    apps['APPS_INCOME_BIRTH_RATIO'] = apps['AMT_INCOME_TOTAL']/apps['DAYS_BIRTH']\n",
        "    apps['APPS_CAR_BIRTH_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_BIRTH']\n",
        "    apps['APPS_CAR_EMPLOYED_RATIO'] = apps['OWN_CAR_AGE'] / apps['DAYS_EMPLOYED']\n",
        "\n",
        "    return apps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mU0PqE9vR4o"
      },
      "source": [
        "#### previous 데이터 가공후 인코딩 및 최종 데이터 집합 생성하는 함수 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOSuDuMvvR4p"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "def get_prev_processed(prev):\n",
        "    # 대출 신청 금액과 실제 대출액/대출 상품금액 차이 및 비율\n",
        "    prev['PREV_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
        "    prev['PREV_GOODS_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_GOODS_PRICE']\n",
        "    prev['PREV_CREDIT_APPL_RATIO'] = prev['AMT_CREDIT']/prev['AMT_APPLICATION']\n",
        "    # prev['PREV_ANNUITY_APPL_RATIO'] = prev['AMT_ANNUITY']/prev['AMT_APPLICATION']\n",
        "    prev['PREV_GOODS_APPL_RATIO'] = prev['AMT_GOODS_PRICE']/prev['AMT_APPLICATION']\n",
        "\n",
        "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
        "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
        "    # 첫번째 만기일과 마지막 만기일까지의 기간\n",
        "    prev['PREV_DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
        "    # 매월 납부 금액과 납부 횟수 곱해서 전체 납부 금액 구함.\n",
        "    all_pay = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
        "    # 전체 납부 금액 대비 AMT_CREDIT 비율을 구하고 여기에 다시 납부횟수로 나누어서 이자율 계산.\n",
        "    prev['PREV_INTERESTS_RATE'] = (all_pay/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n",
        "\n",
        "    return prev\n",
        "\n",
        "\n",
        "def get_prev_amt_agg(prev):\n",
        "    # 새롭게 생성된 대출 신청액 대비 다른 금액 차이 및 비율로 aggregation 수행.\n",
        "    agg_dict = {\n",
        "         # 기존 컬럼.\n",
        "        'SK_ID_CURR':['count'],\n",
        "        'AMT_CREDIT':['mean', 'max', 'sum'],\n",
        "        'AMT_ANNUITY':['mean', 'max', 'sum'],\n",
        "        'AMT_APPLICATION':['mean', 'max', 'sum'],\n",
        "        'AMT_DOWN_PAYMENT':['mean', 'max', 'sum'],\n",
        "        'AMT_GOODS_PRICE':['mean', 'max', 'sum'],\n",
        "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
        "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
        "        'CNT_PAYMENT': ['mean', 'sum'],\n",
        "        # 가공 컬럼\n",
        "        'PREV_CREDIT_DIFF':['mean', 'max', 'sum'],\n",
        "        'PREV_CREDIT_APPL_RATIO':['mean', 'max'],\n",
        "        'PREV_GOODS_DIFF':['mean', 'max', 'sum'],\n",
        "        'PREV_GOODS_APPL_RATIO':['mean', 'max'],\n",
        "        'PREV_DAYS_LAST_DUE_DIFF':['mean', 'max', 'sum'],\n",
        "        'PREV_INTERESTS_RATE':['mean', 'max']\n",
        "    }\n",
        "\n",
        "    prev_group = prev.groupby('SK_ID_CURR')\n",
        "    prev_amt_agg = prev_group.agg(agg_dict)\n",
        "\n",
        "    # multi index 컬럼을 '_'로 연결하여 컬럼명 변경\n",
        "    prev_amt_agg.columns = [\"PREV_\"+ \"_\".join(x).upper() for x in prev_amt_agg.columns.ravel()]\n",
        "\n",
        "    return prev_amt_agg\n",
        "\n",
        "def get_prev_refused_appr_agg(prev):\n",
        "    # 원래 groupby 컬럼 + 세부 기준 컬럼으로 groupby 수행. 세분화된 레벨로 aggregation 수행 한 뒤에 unstack()으로 컬럼레벨로 변형.\n",
        "    prev_refused_appr_group = prev[prev['NAME_CONTRACT_STATUS'].isin(['Approved', 'Refused'])].groupby([ 'SK_ID_CURR', 'NAME_CONTRACT_STATUS'])\n",
        "    prev_refused_appr_agg = prev_refused_appr_group['SK_ID_CURR'].count().unstack()\n",
        "    # 컬럼명 변경.\n",
        "    prev_refused_appr_agg.columns = ['PREV_APPROVED_COUNT', 'PREV_REFUSED_COUNT' ]\n",
        "    # NaN값은 모두 0으로 변경.\n",
        "    prev_refused_appr_agg = prev_refused_appr_agg.fillna(0)\n",
        "\n",
        "    return prev_refused_appr_agg\n",
        "\n",
        "\n",
        "\n",
        "def get_prev_agg(prev):\n",
        "    prev = get_prev_processed(prev)\n",
        "    prev_amt_agg = get_prev_amt_agg(prev)\n",
        "    prev_refused_appr_agg = get_prev_refused_appr_agg(prev)\n",
        "\n",
        "    # prev_amt_agg와 조인.\n",
        "    prev_agg = prev_amt_agg.merge(prev_refused_appr_agg, on='SK_ID_CURR', how='left')\n",
        "    # SK_ID_CURR별 과거 대출건수 대비 APPROVED_COUNT 및 REFUSED_COUNT 비율 생성.\n",
        "    prev_agg['PREV_REFUSED_RATIO'] = prev_agg['PREV_REFUSED_COUNT']/prev_agg['PREV_SK_ID_CURR_COUNT']\n",
        "    prev_agg['PREV_APPROVED_RATIO'] = prev_agg['PREV_APPROVED_COUNT']/prev_agg['PREV_SK_ID_CURR_COUNT']\n",
        "    # 'PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT' 컬럼 drop\n",
        "    prev_agg = prev_agg.drop(['PREV_REFUSED_COUNT', 'PREV_APPROVED_COUNT'], axis=1)\n",
        "\n",
        "    return prev_agg\n",
        "\n",
        "def get_apps_all_with_prev_agg(apps, prev):\n",
        "    apps_all =  get_apps_processed(apps)\n",
        "    prev_agg = get_prev_agg(prev)\n",
        "    print('prev_agg shape:', prev_agg.shape)\n",
        "    print('apps_all before merge shape:', apps_all.shape)\n",
        "    apps_all = apps_all.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
        "    print('apps_all after merge with prev_agg shape:', apps_all.shape)\n",
        "\n",
        "    return apps_all\n",
        "\n",
        "def get_apps_all_encoded(apps_all):\n",
        "    object_columns = apps_all.dtypes[apps_all.dtypes == 'object'].index.tolist()\n",
        "    for column in object_columns:\n",
        "        apps_all[column] = pd.factorize(apps_all[column])[0]\n",
        "\n",
        "    return apps_all\n",
        "\n",
        "def get_apps_all_train_test(apps_all):\n",
        "    apps_all_train = apps_all[~apps_all['TARGET'].isnull()]\n",
        "    apps_all_test = apps_all[apps_all['TARGET'].isnull()]\n",
        "\n",
        "    apps_all_test = apps_all_test.drop('TARGET', axis=1)\n",
        "\n",
        "    return apps_all_train, apps_all_test\n",
        "\n",
        "def train_apps_all(apps_all_train):\n",
        "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=2000,\n",
        "                learning_rate=0.01,\n",
        "                num_leaves=32,\n",
        "                colsample_bytree=0.8,\n",
        "                subsample=0.8,\n",
        "                max_depth=8,\n",
        "                reg_alpha=0.04,\n",
        "                reg_lambda=0.07,\n",
        "                min_child_weight=40,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100,\n",
        "                early_stopping_rounds= 100)\n",
        "\n",
        "    return clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqqmKKhrvR4w"
      },
      "source": [
        "##### 최종 집합 생성 및 인코딩, 학습/테스트 데이터 분리, 학습/검증 피처와 타겟 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "-vsBLQ8FvR4x",
        "outputId": "16575155-27fa-4510-bbb5-7bfe7144f19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prev_agg shape: (338857, 41)\n",
            "apps_all before merge shape: (356255, 135)\n",
            "apps_all after merge with prev_agg shape: (356255, 176)\n"
          ]
        }
      ],
      "source": [
        "apps_all = get_apps_all_with_prev_agg(apps, prev)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "target_app = apps_all_train['TARGET']\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEOB24lVvR47"
      },
      "source": [
        "#### Bayesian Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "MDf92dTOw0rR",
        "outputId": "fbf92f64-95cc-4fed-b03e-def2cc61f2ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.16.0)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp36-none-any.whl size=11685 sha256=09c129c355b994a29ee633dac2fcf5c788727b1ee4aa371a8eae0b07cfac588f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ]
        }
      ],
      "source": [
        "# bayesian optimization 패키지 설치\n",
        "!pip install bayesian-optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDQVRZeRvR48"
      },
      "outputs": [],
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from lightgbm import LGBMClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDmrYrAUvR5B"
      },
      "source": [
        "##### 함수의 입력값 search 범위(하이퍼 파라미터 별 입력 범위) 를 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrIZzOHbvR5C"
      },
      "outputs": [],
      "source": [
        "# parameter 별로 search할 범위를 설정.\n",
        "bayesian_params = {\n",
        "    'max_depth': (6, 16),\n",
        "    'num_leaves': (24, 64),\n",
        "    'min_child_samples': (10, 200),\n",
        "    'min_child_weight':(1, 50),\n",
        "    'subsample':(0.5, 1.0),\n",
        "    'colsample_bytree': (0.5, 1.0),\n",
        "    'max_bin':(10, 500),\n",
        "    'reg_lambda':(0.001, 10),\n",
        "    'reg_alpha': (0.01, 50)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yog23y34vR5H"
      },
      "source": [
        "##### 최대 값을 구할 함수 선언.\n",
        "* iteration 시 마다 hyperparameter를 입력받아 classifier 학습하고 roc_auc_score값을 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YduL1j4RvR5J"
      },
      "outputs": [],
      "source": [
        "def lgb_roc_eval(max_depth, num_leaves, min_child_samples, min_child_weight, subsample,\n",
        "                colsample_bytree,max_bin, reg_lambda, reg_alpha):\n",
        "    params = {\n",
        "        \"n_estimators\":500, \"learning_rate\":0.02,\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경\n",
        "        'num_leaves': int(round(num_leaves)),\n",
        "        'min_child_samples': int(round(min_child_samples)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'subsample': max(min(subsample, 1), 0),\n",
        "        'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'reg_lambda': max(reg_lambda,0),\n",
        "        'reg_alpha': max(reg_alpha, 0)\n",
        "    }\n",
        "    lgb_model = LGBMClassifier(**params)\n",
        "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100,\n",
        "                early_stopping_rounds= 100)\n",
        "    valid_proba = lgb_model.predict_proba(valid_x)[:, 1]\n",
        "    roc_auc = roc_auc_score(valid_y, valid_proba)\n",
        "\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmnQwMudvR5Q"
      },
      "source": [
        "##### BayesianOptimization 객체 생성 후 함수 반환값이 최대가 되는 입력값 search를 위한 iteration 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vcny5qJrvR5R",
        "outputId": "4f6708e1-b153-40c8-a0e7-98880aea2310",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | colsam... |  max_bin  | max_depth | min_ch... | min_ch... | num_le... | reg_alpha | reg_la... | subsample |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246055\ttraining's auc: 0.769441\tvalid_1's binary_logloss: 0.248931\tvalid_1's auc: 0.755295\n",
            "[200]\ttraining's binary_logloss: 0.238455\ttraining's auc: 0.787337\tvalid_1's binary_logloss: 0.244205\tvalid_1's auc: 0.766208\n",
            "[300]\ttraining's binary_logloss: 0.234009\ttraining's auc: 0.798843\tvalid_1's binary_logloss: 0.242347\tvalid_1's auc: 0.771365\n",
            "[400]\ttraining's binary_logloss: 0.230658\ttraining's auc: 0.807905\tvalid_1's binary_logloss: 0.241451\tvalid_1's auc: 0.773881\n",
            "[500]\ttraining's binary_logloss: 0.227681\ttraining's auc: 0.816051\tvalid_1's binary_logloss: 0.240888\tvalid_1's auc: 0.775474\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.227681\ttraining's auc: 0.816051\tvalid_1's binary_logloss: 0.240888\tvalid_1's auc: 0.775474\n",
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7755  \u001b[0m | \u001b[0m 0.7744  \u001b[0m | \u001b[0m 360.4   \u001b[0m | \u001b[0m 12.03   \u001b[0m | \u001b[0m 113.5   \u001b[0m | \u001b[0m 21.76   \u001b[0m | \u001b[0m 49.84   \u001b[0m | \u001b[0m 21.88   \u001b[0m | \u001b[0m 8.918   \u001b[0m | \u001b[0m 0.9818  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.247403\ttraining's auc: 0.762607\tvalid_1's binary_logloss: 0.249078\tvalid_1's auc: 0.753906\n",
            "[200]\ttraining's binary_logloss: 0.240422\ttraining's auc: 0.780221\tvalid_1's binary_logloss: 0.244242\tvalid_1's auc: 0.765727\n",
            "[300]\ttraining's binary_logloss: 0.236479\ttraining's auc: 0.790896\tvalid_1's binary_logloss: 0.242327\tvalid_1's auc: 0.77103\n",
            "[400]\ttraining's binary_logloss: 0.233521\ttraining's auc: 0.799101\tvalid_1's binary_logloss: 0.2413\tvalid_1's auc: 0.773901\n",
            "[500]\ttraining's binary_logloss: 0.231078\ttraining's auc: 0.805962\tvalid_1's binary_logloss: 0.240762\tvalid_1's auc: 0.775357\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.231078\ttraining's auc: 0.805962\tvalid_1's binary_logloss: 0.240762\tvalid_1's auc: 0.775357\n",
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7754  \u001b[0m | \u001b[0m 0.6917  \u001b[0m | \u001b[0m 397.9   \u001b[0m | \u001b[0m 11.29   \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 46.35   \u001b[0m | \u001b[0m 26.84   \u001b[0m | \u001b[0m 4.366   \u001b[0m | \u001b[0m 0.2032  \u001b[0m | \u001b[0m 0.9163  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243787\ttraining's auc: 0.775984\tvalid_1's binary_logloss: 0.247887\tvalid_1's auc: 0.757669\n",
            "[200]\ttraining's binary_logloss: 0.234957\ttraining's auc: 0.797205\tvalid_1's binary_logloss: 0.243121\tvalid_1's auc: 0.769013\n",
            "[300]\ttraining's binary_logloss: 0.22917\ttraining's auc: 0.812302\tvalid_1's binary_logloss: 0.241429\tvalid_1's auc: 0.773828\n",
            "[400]\ttraining's binary_logloss: 0.224408\ttraining's auc: 0.824959\tvalid_1's binary_logloss: 0.240536\tvalid_1's auc: 0.776324\n",
            "[500]\ttraining's binary_logloss: 0.220334\ttraining's auc: 0.835945\tvalid_1's binary_logloss: 0.240167\tvalid_1's auc: 0.777332\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.220334\ttraining's auc: 0.835945\tvalid_1's binary_logloss: 0.240167\tvalid_1's auc: 0.777332\n",
            "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7773  \u001b[0m | \u001b[95m 0.8891  \u001b[0m | \u001b[95m 436.3   \u001b[0m | \u001b[95m 15.79   \u001b[0m | \u001b[95m 161.8   \u001b[0m | \u001b[95m 23.61   \u001b[0m | \u001b[95m 55.22   \u001b[0m | \u001b[95m 5.923   \u001b[0m | \u001b[95m 6.4     \u001b[0m | \u001b[95m 0.5717  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246899\ttraining's auc: 0.765744\tvalid_1's binary_logloss: 0.249215\tvalid_1's auc: 0.753886\n",
            "[200]\ttraining's binary_logloss: 0.239831\ttraining's auc: 0.782824\tvalid_1's binary_logloss: 0.24453\tvalid_1's auc: 0.765228\n",
            "[300]\ttraining's binary_logloss: 0.235787\ttraining's auc: 0.79353\tvalid_1's binary_logloss: 0.2426\tvalid_1's auc: 0.770618\n",
            "[400]\ttraining's binary_logloss: 0.232814\ttraining's auc: 0.801566\tvalid_1's binary_logloss: 0.241576\tvalid_1's auc: 0.773499\n",
            "[500]\ttraining's binary_logloss: 0.230355\ttraining's auc: 0.808263\tvalid_1's binary_logloss: 0.241041\tvalid_1's auc: 0.774994\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.230355\ttraining's auc: 0.808263\tvalid_1's binary_logloss: 0.241041\tvalid_1's auc: 0.774994\n",
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.775   \u001b[0m | \u001b[0m 0.9723  \u001b[0m | \u001b[0m 265.7   \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 60.27   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 42.25   \u001b[0m | \u001b[0m 28.43   \u001b[0m | \u001b[0m 0.1889  \u001b[0m | \u001b[0m 0.8088  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.247324\ttraining's auc: 0.765749\tvalid_1's binary_logloss: 0.249617\tvalid_1's auc: 0.753702\n",
            "[200]\ttraining's binary_logloss: 0.240353\ttraining's auc: 0.781611\tvalid_1's binary_logloss: 0.244878\tvalid_1's auc: 0.764481\n",
            "[300]\ttraining's binary_logloss: 0.236528\ttraining's auc: 0.791576\tvalid_1's binary_logloss: 0.242979\tvalid_1's auc: 0.769669\n",
            "[400]\ttraining's binary_logloss: 0.233771\ttraining's auc: 0.799079\tvalid_1's binary_logloss: 0.242037\tvalid_1's auc: 0.772325\n",
            "[500]\ttraining's binary_logloss: 0.231415\ttraining's auc: 0.805611\tvalid_1's binary_logloss: 0.241404\tvalid_1's auc: 0.774198\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.231415\ttraining's auc: 0.805611\tvalid_1's binary_logloss: 0.241404\tvalid_1's auc: 0.774198\n",
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7742  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 312.3   \u001b[0m | \u001b[0m 15.44   \u001b[0m | \u001b[0m 139.5   \u001b[0m | \u001b[0m 18.62   \u001b[0m | \u001b[0m 41.48   \u001b[0m | \u001b[0m 34.88   \u001b[0m | \u001b[0m 0.6032  \u001b[0m | \u001b[0m 0.8334  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24729\ttraining's auc: 0.765974\tvalid_1's binary_logloss: 0.249608\tvalid_1's auc: 0.753298\n",
            "[200]\ttraining's binary_logloss: 0.240351\ttraining's auc: 0.782182\tvalid_1's binary_logloss: 0.244735\tvalid_1's auc: 0.764937\n",
            "[300]\ttraining's binary_logloss: 0.236658\ttraining's auc: 0.791597\tvalid_1's binary_logloss: 0.242811\tvalid_1's auc: 0.770094\n",
            "[400]\ttraining's binary_logloss: 0.234003\ttraining's auc: 0.798618\tvalid_1's binary_logloss: 0.241848\tvalid_1's auc: 0.772785\n",
            "[500]\ttraining's binary_logloss: 0.231862\ttraining's auc: 0.80432\tvalid_1's binary_logloss: 0.241265\tvalid_1's auc: 0.774314\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.231862\ttraining's auc: 0.80432\tvalid_1's binary_logloss: 0.241265\tvalid_1's auc: 0.774314\n",
            "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7743  \u001b[0m | \u001b[0m 0.8538  \u001b[0m | \u001b[0m 499.2   \u001b[0m | \u001b[0m 7.119   \u001b[0m | \u001b[0m 10.4    \u001b[0m | \u001b[0m 37.64   \u001b[0m | \u001b[0m 46.75   \u001b[0m | \u001b[0m 34.55   \u001b[0m | \u001b[0m 7.535   \u001b[0m | \u001b[0m 0.7468  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246977\ttraining's auc: 0.765969\tvalid_1's binary_logloss: 0.249416\tvalid_1's auc: 0.753264\n",
            "[200]\ttraining's binary_logloss: 0.239697\ttraining's auc: 0.78383\tvalid_1's binary_logloss: 0.244979\tvalid_1's auc: 0.76387\n",
            "[300]\ttraining's binary_logloss: 0.235487\ttraining's auc: 0.795076\tvalid_1's binary_logloss: 0.243362\tvalid_1's auc: 0.768285\n",
            "[400]\ttraining's binary_logloss: 0.232212\ttraining's auc: 0.804034\tvalid_1's binary_logloss: 0.242589\tvalid_1's auc: 0.770586\n",
            "[500]\ttraining's binary_logloss: 0.22931\ttraining's auc: 0.812016\tvalid_1's binary_logloss: 0.242104\tvalid_1's auc: 0.772006\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.22931\ttraining's auc: 0.812016\tvalid_1's binary_logloss: 0.242104\tvalid_1's auc: 0.772006\n",
            "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.772   \u001b[0m | \u001b[0m 0.9751  \u001b[0m | \u001b[0m 12.5    \u001b[0m | \u001b[0m 15.87   \u001b[0m | \u001b[0m 199.1   \u001b[0m | \u001b[0m 43.33   \u001b[0m | \u001b[0m 53.78   \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 9.61    \u001b[0m | \u001b[0m 0.7368  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.245827\ttraining's auc: 0.772591\tvalid_1's binary_logloss: 0.248613\tvalid_1's auc: 0.757999\n",
            "[200]\ttraining's binary_logloss: 0.23821\ttraining's auc: 0.788947\tvalid_1's binary_logloss: 0.243834\tvalid_1's auc: 0.767444\n",
            "[300]\ttraining's binary_logloss: 0.233809\ttraining's auc: 0.800036\tvalid_1's binary_logloss: 0.242037\tvalid_1's auc: 0.772049\n",
            "[400]\ttraining's binary_logloss: 0.230765\ttraining's auc: 0.807812\tvalid_1's binary_logloss: 0.241178\tvalid_1's auc: 0.774289\n",
            "[500]\ttraining's binary_logloss: 0.228071\ttraining's auc: 0.815026\tvalid_1's binary_logloss: 0.240678\tvalid_1's auc: 0.775654\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.228071\ttraining's auc: 0.815026\tvalid_1's binary_logloss: 0.240678\tvalid_1's auc: 0.775654\n",
            "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7757  \u001b[0m | \u001b[0m 0.5607  \u001b[0m | \u001b[0m 497.7   \u001b[0m | \u001b[0m 7.087   \u001b[0m | \u001b[0m 199.5   \u001b[0m | \u001b[0m 48.53   \u001b[0m | \u001b[0m 46.57   \u001b[0m | \u001b[0m 8.796   \u001b[0m | \u001b[0m 5.276   \u001b[0m | \u001b[0m 0.8411  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.248462\ttraining's auc: 0.760337\tvalid_1's binary_logloss: 0.25014\tvalid_1's auc: 0.751039\n",
            "[200]\ttraining's binary_logloss: 0.241973\ttraining's auc: 0.776251\tvalid_1's binary_logloss: 0.245444\tvalid_1's auc: 0.762675\n",
            "[300]\ttraining's binary_logloss: 0.238475\ttraining's auc: 0.785699\tvalid_1's binary_logloss: 0.24349\tvalid_1's auc: 0.768207\n",
            "[400]\ttraining's binary_logloss: 0.236043\ttraining's auc: 0.792287\tvalid_1's binary_logloss: 0.242475\tvalid_1's auc: 0.771064\n",
            "[500]\ttraining's binary_logloss: 0.234105\ttraining's auc: 0.797673\tvalid_1's binary_logloss: 0.241873\tvalid_1's auc: 0.772756\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.234105\ttraining's auc: 0.797673\tvalid_1's binary_logloss: 0.241873\tvalid_1's auc: 0.772756\n",
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7728  \u001b[0m | \u001b[0m 0.9722  \u001b[0m | \u001b[0m 497.8   \u001b[0m | \u001b[0m 15.76   \u001b[0m | \u001b[0m 197.6   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 32.35   \u001b[0m | \u001b[0m 43.15   \u001b[0m | \u001b[0m 0.1655  \u001b[0m | \u001b[0m 0.6483  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.246026\ttraining's auc: 0.770519\tvalid_1's binary_logloss: 0.24849\tvalid_1's auc: 0.758188\n",
            "[200]\ttraining's binary_logloss: 0.238356\ttraining's auc: 0.787168\tvalid_1's binary_logloss: 0.243546\tvalid_1's auc: 0.768022\n",
            "[300]\ttraining's binary_logloss: 0.233805\ttraining's auc: 0.799067\tvalid_1's binary_logloss: 0.241798\tvalid_1's auc: 0.772513\n",
            "[400]\ttraining's binary_logloss: 0.230316\ttraining's auc: 0.808398\tvalid_1's binary_logloss: 0.24088\tvalid_1's auc: 0.775054\n",
            "[500]\ttraining's binary_logloss: 0.227288\ttraining's auc: 0.816777\tvalid_1's binary_logloss: 0.24038\tvalid_1's auc: 0.776491\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.227288\ttraining's auc: 0.816777\tvalid_1's binary_logloss: 0.24038\tvalid_1's auc: 0.776491\n",
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.5342  \u001b[0m | \u001b[0m 489.9   \u001b[0m | \u001b[0m 8.998   \u001b[0m | \u001b[0m 10.21   \u001b[0m | \u001b[0m 39.73   \u001b[0m | \u001b[0m 36.51   \u001b[0m | \u001b[0m 1.809   \u001b[0m | \u001b[0m 5.04    \u001b[0m | \u001b[0m 0.5383  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242511\ttraining's auc: 0.780728\tvalid_1's binary_logloss: 0.247498\tvalid_1's auc: 0.759611\n",
            "[200]\ttraining's binary_logloss: 0.232956\ttraining's auc: 0.803019\tvalid_1's binary_logloss: 0.242928\tvalid_1's auc: 0.769376\n",
            "[300]\ttraining's binary_logloss: 0.226632\ttraining's auc: 0.819394\tvalid_1's binary_logloss: 0.241396\tvalid_1's auc: 0.773595\n",
            "[400]\ttraining's binary_logloss: 0.221355\ttraining's auc: 0.833168\tvalid_1's binary_logloss: 0.240554\tvalid_1's auc: 0.775995\n",
            "[500]\ttraining's binary_logloss: 0.216921\ttraining's auc: 0.844707\tvalid_1's binary_logloss: 0.240233\tvalid_1's auc: 0.776863\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.216921\ttraining's auc: 0.844707\tvalid_1's binary_logloss: 0.240233\tvalid_1's auc: 0.776863\n",
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7769  \u001b[0m | \u001b[0m 0.6872  \u001b[0m | \u001b[0m 479.6   \u001b[0m | \u001b[0m 10.23   \u001b[0m | \u001b[0m 24.87   \u001b[0m | \u001b[0m 6.99    \u001b[0m | \u001b[0m 60.1    \u001b[0m | \u001b[0m 0.8071  \u001b[0m | \u001b[0m 5.777   \u001b[0m | \u001b[0m 0.7787  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24234\ttraining's auc: 0.781101\tvalid_1's binary_logloss: 0.24728\tvalid_1's auc: 0.760147\n",
            "[200]\ttraining's binary_logloss: 0.2327\ttraining's auc: 0.803437\tvalid_1's binary_logloss: 0.24258\tvalid_1's auc: 0.770345\n",
            "[300]\ttraining's binary_logloss: 0.22623\ttraining's auc: 0.82016\tvalid_1's binary_logloss: 0.241016\tvalid_1's auc: 0.77462\n",
            "[400]\ttraining's binary_logloss: 0.220907\ttraining's auc: 0.834068\tvalid_1's binary_logloss: 0.24032\tvalid_1's auc: 0.776459\n",
            "[500]\ttraining's binary_logloss: 0.21622\ttraining's auc: 0.846267\tvalid_1's binary_logloss: 0.239929\tvalid_1's auc: 0.777578\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.21622\ttraining's auc: 0.846267\tvalid_1's binary_logloss: 0.239929\tvalid_1's auc: 0.777578\n",
            "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.7776  \u001b[0m | \u001b[95m 0.6874  \u001b[0m | \u001b[95m 479.6   \u001b[0m | \u001b[95m 15.62   \u001b[0m | \u001b[95m 15.73   \u001b[0m | \u001b[95m 46.02   \u001b[0m | \u001b[95m 60.62   \u001b[0m | \u001b[95m 0.6881  \u001b[0m | \u001b[95m 2.142   \u001b[0m | \u001b[95m 0.9413  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242621\ttraining's auc: 0.777962\tvalid_1's binary_logloss: 0.247394\tvalid_1's auc: 0.758094\n",
            "[200]\ttraining's binary_logloss: 0.23316\ttraining's auc: 0.801477\tvalid_1's binary_logloss: 0.242854\tvalid_1's auc: 0.769493\n",
            "[300]\ttraining's binary_logloss: 0.226772\ttraining's auc: 0.818268\tvalid_1's binary_logloss: 0.241209\tvalid_1's auc: 0.77417\n",
            "[400]\ttraining's binary_logloss: 0.221626\ttraining's auc: 0.831748\tvalid_1's binary_logloss: 0.240519\tvalid_1's auc: 0.776221\n",
            "[500]\ttraining's binary_logloss: 0.217126\ttraining's auc: 0.843541\tvalid_1's binary_logloss: 0.240284\tvalid_1's auc: 0.776981\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.217126\ttraining's auc: 0.843541\tvalid_1's binary_logloss: 0.240284\tvalid_1's auc: 0.776981\n",
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.777   \u001b[0m | \u001b[0m 0.9558  \u001b[0m | \u001b[0m 493.2   \u001b[0m | \u001b[0m 15.27   \u001b[0m | \u001b[0m 18.25   \u001b[0m | \u001b[0m 40.87   \u001b[0m | \u001b[0m 55.51   \u001b[0m | \u001b[0m 0.4371  \u001b[0m | \u001b[0m 1.348   \u001b[0m | \u001b[0m 0.9353  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.245377\ttraining's auc: 0.770294\tvalid_1's binary_logloss: 0.248285\tvalid_1's auc: 0.756901\n",
            "[200]\ttraining's binary_logloss: 0.237373\ttraining's auc: 0.790013\tvalid_1's binary_logloss: 0.243599\tvalid_1's auc: 0.767528\n",
            "[300]\ttraining's binary_logloss: 0.232274\ttraining's auc: 0.803834\tvalid_1's binary_logloss: 0.241778\tvalid_1's auc: 0.772592\n",
            "[400]\ttraining's binary_logloss: 0.228236\ttraining's auc: 0.814922\tvalid_1's binary_logloss: 0.240883\tvalid_1's auc: 0.775084\n",
            "[500]\ttraining's binary_logloss: 0.224852\ttraining's auc: 0.824481\tvalid_1's binary_logloss: 0.240454\tvalid_1's auc: 0.776298\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.224852\ttraining's auc: 0.824481\tvalid_1's binary_logloss: 0.240454\tvalid_1's auc: 0.776298\n",
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7763  \u001b[0m | \u001b[0m 0.6557  \u001b[0m | \u001b[0m 489.9   \u001b[0m | \u001b[0m 10.31   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 1.049   \u001b[0m | \u001b[0m 37.8    \u001b[0m | \u001b[0m 1.685   \u001b[0m | \u001b[0m 1.641   \u001b[0m | \u001b[0m 0.5974  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243502\ttraining's auc: 0.779578\tvalid_1's binary_logloss: 0.247815\tvalid_1's auc: 0.759968\n",
            "[200]\ttraining's binary_logloss: 0.234257\ttraining's auc: 0.799832\tvalid_1's binary_logloss: 0.242909\tvalid_1's auc: 0.769824\n",
            "[300]\ttraining's binary_logloss: 0.228301\ttraining's auc: 0.815048\tvalid_1's binary_logloss: 0.241274\tvalid_1's auc: 0.773989\n",
            "[400]\ttraining's binary_logloss: 0.223315\ttraining's auc: 0.82824\tvalid_1's binary_logloss: 0.240403\tvalid_1's auc: 0.776412\n",
            "[500]\ttraining's binary_logloss: 0.218993\ttraining's auc: 0.839625\tvalid_1's binary_logloss: 0.240016\tvalid_1's auc: 0.777459\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218993\ttraining's auc: 0.839625\tvalid_1's binary_logloss: 0.240016\tvalid_1's auc: 0.777459\n",
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7775  \u001b[0m | \u001b[0m 0.5838  \u001b[0m | \u001b[0m 478.1   \u001b[0m | \u001b[0m 15.33   \u001b[0m | \u001b[0m 16.94   \u001b[0m | \u001b[0m 43.66   \u001b[0m | \u001b[0m 58.1    \u001b[0m | \u001b[0m 1.873   \u001b[0m | \u001b[0m 6.926   \u001b[0m | \u001b[0m 0.821   \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24262\ttraining's auc: 0.780136\tvalid_1's binary_logloss: 0.247505\tvalid_1's auc: 0.758714\n",
            "[200]\ttraining's binary_logloss: 0.233017\ttraining's auc: 0.802917\tvalid_1's binary_logloss: 0.242809\tvalid_1's auc: 0.769682\n",
            "[300]\ttraining's binary_logloss: 0.22659\ttraining's auc: 0.819451\tvalid_1's binary_logloss: 0.241334\tvalid_1's auc: 0.773752\n",
            "[400]\ttraining's binary_logloss: 0.221277\ttraining's auc: 0.833328\tvalid_1's binary_logloss: 0.240514\tvalid_1's auc: 0.776042\n",
            "[500]\ttraining's binary_logloss: 0.216682\ttraining's auc: 0.845115\tvalid_1's binary_logloss: 0.240115\tvalid_1's auc: 0.777182\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.216682\ttraining's auc: 0.845115\tvalid_1's binary_logloss: 0.240115\tvalid_1's auc: 0.777182\n",
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7772  \u001b[0m | \u001b[0m 0.879   \u001b[0m | \u001b[0m 487.3   \u001b[0m | \u001b[0m 13.74   \u001b[0m | \u001b[0m 22.79   \u001b[0m | \u001b[0m 47.05   \u001b[0m | \u001b[0m 63.32   \u001b[0m | \u001b[0m 1.131   \u001b[0m | \u001b[0m 9.356   \u001b[0m | \u001b[0m 0.8718  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243214\ttraining's auc: 0.778553\tvalid_1's binary_logloss: 0.247681\tvalid_1's auc: 0.759151\n",
            "[200]\ttraining's binary_logloss: 0.233945\ttraining's auc: 0.800338\tvalid_1's binary_logloss: 0.242867\tvalid_1's auc: 0.769981\n",
            "[300]\ttraining's binary_logloss: 0.227839\ttraining's auc: 0.816293\tvalid_1's binary_logloss: 0.241216\tvalid_1's auc: 0.774466\n",
            "[400]\ttraining's binary_logloss: 0.222764\ttraining's auc: 0.829769\tvalid_1's binary_logloss: 0.240344\tvalid_1's auc: 0.77684\n",
            "[500]\ttraining's binary_logloss: 0.218495\ttraining's auc: 0.84098\tvalid_1's binary_logloss: 0.239917\tvalid_1's auc: 0.778048\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218495\ttraining's auc: 0.84098\tvalid_1's binary_logloss: 0.239917\tvalid_1's auc: 0.778048\n",
            "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.778   \u001b[0m | \u001b[95m 0.7437  \u001b[0m | \u001b[95m 494.7   \u001b[0m | \u001b[95m 14.27   \u001b[0m | \u001b[95m 25.78   \u001b[0m | \u001b[95m 2.691   \u001b[0m | \u001b[95m 57.97   \u001b[0m | \u001b[95m 2.47    \u001b[0m | \u001b[95m 9.797   \u001b[0m | \u001b[95m 0.5824  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243089\ttraining's auc: 0.779663\tvalid_1's binary_logloss: 0.247772\tvalid_1's auc: 0.759328\n",
            "[200]\ttraining's binary_logloss: 0.233916\ttraining's auc: 0.800579\tvalid_1's binary_logloss: 0.242989\tvalid_1's auc: 0.769592\n",
            "[300]\ttraining's binary_logloss: 0.227961\ttraining's auc: 0.81581\tvalid_1's binary_logloss: 0.24136\tvalid_1's auc: 0.773922\n",
            "[400]\ttraining's binary_logloss: 0.223086\ttraining's auc: 0.828448\tvalid_1's binary_logloss: 0.240452\tvalid_1's auc: 0.776537\n",
            "[500]\ttraining's binary_logloss: 0.218765\ttraining's auc: 0.839689\tvalid_1's binary_logloss: 0.239969\tvalid_1's auc: 0.777791\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218765\ttraining's auc: 0.839689\tvalid_1's binary_logloss: 0.239969\tvalid_1's auc: 0.777791\n",
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7778  \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 467.5   \u001b[0m | \u001b[0m 10.23   \u001b[0m | \u001b[0m 22.57   \u001b[0m | \u001b[0m 3.607   \u001b[0m | \u001b[0m 62.53   \u001b[0m | \u001b[0m 5.255   \u001b[0m | \u001b[0m 8.662   \u001b[0m | \u001b[0m 0.7036  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243329\ttraining's auc: 0.780078\tvalid_1's binary_logloss: 0.247818\tvalid_1's auc: 0.760092\n",
            "[200]\ttraining's binary_logloss: 0.234107\ttraining's auc: 0.800394\tvalid_1's binary_logloss: 0.242928\tvalid_1's auc: 0.770018\n",
            "[300]\ttraining's binary_logloss: 0.228138\ttraining's auc: 0.815651\tvalid_1's binary_logloss: 0.241298\tvalid_1's auc: 0.774223\n",
            "[400]\ttraining's binary_logloss: 0.223197\ttraining's auc: 0.828422\tvalid_1's binary_logloss: 0.240427\tvalid_1's auc: 0.776583\n",
            "[500]\ttraining's binary_logloss: 0.218904\ttraining's auc: 0.83973\tvalid_1's binary_logloss: 0.23993\tvalid_1's auc: 0.777942\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218904\ttraining's auc: 0.83973\tvalid_1's binary_logloss: 0.23993\tvalid_1's auc: 0.777942\n",
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7779  \u001b[0m | \u001b[0m 0.5437  \u001b[0m | \u001b[0m 488.4   \u001b[0m | \u001b[0m 10.29   \u001b[0m | \u001b[0m 45.29   \u001b[0m | \u001b[0m 1.819   \u001b[0m | \u001b[0m 62.43   \u001b[0m | \u001b[0m 3.419   \u001b[0m | \u001b[0m 9.019   \u001b[0m | \u001b[0m 0.6595  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.244805\ttraining's auc: 0.775537\tvalid_1's binary_logloss: 0.248491\tvalid_1's auc: 0.756923\n",
            "[200]\ttraining's binary_logloss: 0.236787\ttraining's auc: 0.794163\tvalid_1's binary_logloss: 0.243937\tvalid_1's auc: 0.766883\n",
            "[300]\ttraining's binary_logloss: 0.232062\ttraining's auc: 0.806155\tvalid_1's binary_logloss: 0.242106\tvalid_1's auc: 0.771886\n",
            "[400]\ttraining's binary_logloss: 0.228602\ttraining's auc: 0.814888\tvalid_1's binary_logloss: 0.241263\tvalid_1's auc: 0.774125\n",
            "[500]\ttraining's binary_logloss: 0.225643\ttraining's auc: 0.822414\tvalid_1's binary_logloss: 0.240776\tvalid_1's auc: 0.775568\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.225643\ttraining's auc: 0.822414\tvalid_1's binary_logloss: 0.240776\tvalid_1's auc: 0.775568\n",
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7756  \u001b[0m | \u001b[0m 0.7745  \u001b[0m | \u001b[0m 488.7   \u001b[0m | \u001b[0m 6.037   \u001b[0m | \u001b[0m 34.42   \u001b[0m | \u001b[0m 5.833   \u001b[0m | \u001b[0m 60.81   \u001b[0m | \u001b[0m 7.308   \u001b[0m | \u001b[0m 0.9877  \u001b[0m | \u001b[0m 0.5466  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243236\ttraining's auc: 0.779669\tvalid_1's binary_logloss: 0.247666\tvalid_1's auc: 0.759311\n",
            "[200]\ttraining's binary_logloss: 0.234339\ttraining's auc: 0.799996\tvalid_1's binary_logloss: 0.243003\tvalid_1's auc: 0.769514\n",
            "[300]\ttraining's binary_logloss: 0.229103\ttraining's auc: 0.813046\tvalid_1's binary_logloss: 0.241444\tvalid_1's auc: 0.773553\n",
            "[400]\ttraining's binary_logloss: 0.22518\ttraining's auc: 0.823131\tvalid_1's binary_logloss: 0.240737\tvalid_1's auc: 0.775455\n",
            "[500]\ttraining's binary_logloss: 0.221873\ttraining's auc: 0.831569\tvalid_1's binary_logloss: 0.240306\tvalid_1's auc: 0.77665\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.221873\ttraining's auc: 0.831569\tvalid_1's binary_logloss: 0.240306\tvalid_1's auc: 0.77665\n",
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7767  \u001b[0m | \u001b[0m 0.7307  \u001b[0m | \u001b[0m 497.6   \u001b[0m | \u001b[0m 7.704   \u001b[0m | \u001b[0m 43.93   \u001b[0m | \u001b[0m 49.29   \u001b[0m | \u001b[0m 62.3    \u001b[0m | \u001b[0m 2.761   \u001b[0m | \u001b[0m 6.593   \u001b[0m | \u001b[0m 0.7549  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242137\ttraining's auc: 0.781639\tvalid_1's binary_logloss: 0.247503\tvalid_1's auc: 0.758526\n",
            "[200]\ttraining's binary_logloss: 0.23263\ttraining's auc: 0.805126\tvalid_1's binary_logloss: 0.243107\tvalid_1's auc: 0.768976\n",
            "[300]\ttraining's binary_logloss: 0.22657\ttraining's auc: 0.820635\tvalid_1's binary_logloss: 0.241573\tvalid_1's auc: 0.773201\n",
            "[400]\ttraining's binary_logloss: 0.222158\ttraining's auc: 0.832226\tvalid_1's binary_logloss: 0.240913\tvalid_1's auc: 0.775071\n",
            "[500]\ttraining's binary_logloss: 0.217876\ttraining's auc: 0.84362\tvalid_1's binary_logloss: 0.24046\tvalid_1's auc: 0.776496\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.217876\ttraining's auc: 0.84362\tvalid_1's binary_logloss: 0.24046\tvalid_1's auc: 0.776496\n",
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.9702  \u001b[0m | \u001b[0m 490.2   \u001b[0m | \u001b[0m 6.676   \u001b[0m | \u001b[0m 130.6   \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 62.38   \u001b[0m | \u001b[0m 1.419   \u001b[0m | \u001b[0m 0.3271  \u001b[0m | \u001b[0m 0.5556  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.244754\ttraining's auc: 0.776863\tvalid_1's binary_logloss: 0.248357\tvalid_1's auc: 0.758584\n",
            "[200]\ttraining's binary_logloss: 0.236514\ttraining's auc: 0.79531\tvalid_1's binary_logloss: 0.243758\tvalid_1's auc: 0.767616\n",
            "[300]\ttraining's binary_logloss: 0.231616\ttraining's auc: 0.807759\tvalid_1's binary_logloss: 0.241993\tvalid_1's auc: 0.772192\n",
            "[400]\ttraining's binary_logloss: 0.227928\ttraining's auc: 0.816863\tvalid_1's binary_logloss: 0.241086\tvalid_1's auc: 0.774506\n",
            "[500]\ttraining's binary_logloss: 0.224791\ttraining's auc: 0.824982\tvalid_1's binary_logloss: 0.240589\tvalid_1's auc: 0.775856\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.224791\ttraining's auc: 0.824982\tvalid_1's binary_logloss: 0.240589\tvalid_1's auc: 0.775856\n",
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.594   \u001b[0m | \u001b[0m 493.5   \u001b[0m | \u001b[0m 6.165   \u001b[0m | \u001b[0m 26.6    \u001b[0m | \u001b[0m 1.477   \u001b[0m | \u001b[0m 60.15   \u001b[0m | \u001b[0m 4.686   \u001b[0m | \u001b[0m 2.352   \u001b[0m | \u001b[0m 0.9888  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242193\ttraining's auc: 0.780768\tvalid_1's binary_logloss: 0.247238\tvalid_1's auc: 0.75918\n",
            "[200]\ttraining's binary_logloss: 0.23266\ttraining's auc: 0.803494\tvalid_1's binary_logloss: 0.242822\tvalid_1's auc: 0.769601\n",
            "[300]\ttraining's binary_logloss: 0.226701\ttraining's auc: 0.818631\tvalid_1's binary_logloss: 0.241548\tvalid_1's auc: 0.772958\n",
            "[400]\ttraining's binary_logloss: 0.22223\ttraining's auc: 0.830276\tvalid_1's binary_logloss: 0.240774\tvalid_1's auc: 0.775298\n",
            "[500]\ttraining's binary_logloss: 0.218401\ttraining's auc: 0.840332\tvalid_1's binary_logloss: 0.240327\tvalid_1's auc: 0.776645\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.218401\ttraining's auc: 0.840332\tvalid_1's binary_logloss: 0.240327\tvalid_1's auc: 0.776645\n",
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7766  \u001b[0m | \u001b[0m 0.9335  \u001b[0m | \u001b[0m 495.5   \u001b[0m | \u001b[0m 9.276   \u001b[0m | \u001b[0m 21.97   \u001b[0m | \u001b[0m 43.59   \u001b[0m | \u001b[0m 63.13   \u001b[0m | \u001b[0m 0.3813  \u001b[0m | \u001b[0m 4.526   \u001b[0m | \u001b[0m 0.5504  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24718\ttraining's auc: 0.763464\tvalid_1's binary_logloss: 0.249003\tvalid_1's auc: 0.75396\n",
            "[200]\ttraining's binary_logloss: 0.239976\ttraining's auc: 0.781626\tvalid_1's binary_logloss: 0.244136\tvalid_1's auc: 0.765987\n",
            "[300]\ttraining's binary_logloss: 0.235751\ttraining's auc: 0.7932\tvalid_1's binary_logloss: 0.242137\tvalid_1's auc: 0.771646\n",
            "[400]\ttraining's binary_logloss: 0.232543\ttraining's auc: 0.802154\tvalid_1's binary_logloss: 0.241049\tvalid_1's auc: 0.77476\n",
            "[500]\ttraining's binary_logloss: 0.230017\ttraining's auc: 0.809313\tvalid_1's binary_logloss: 0.240593\tvalid_1's auc: 0.775998\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.230017\ttraining's auc: 0.809313\tvalid_1's binary_logloss: 0.240593\tvalid_1's auc: 0.775998\n",
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.776   \u001b[0m | \u001b[0m 0.861   \u001b[0m | \u001b[0m 492.5   \u001b[0m | \u001b[0m 12.7    \u001b[0m | \u001b[0m 15.12   \u001b[0m | \u001b[0m 1.937   \u001b[0m | \u001b[0m 27.72   \u001b[0m | \u001b[0m 1.034   \u001b[0m | \u001b[0m 8.386   \u001b[0m | \u001b[0m 0.6302  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24348\ttraining's auc: 0.77895\tvalid_1's binary_logloss: 0.247784\tvalid_1's auc: 0.759417\n",
            "[200]\ttraining's binary_logloss: 0.234628\ttraining's auc: 0.798731\tvalid_1's binary_logloss: 0.243105\tvalid_1's auc: 0.76931\n",
            "[300]\ttraining's binary_logloss: 0.228824\ttraining's auc: 0.813704\tvalid_1's binary_logloss: 0.241488\tvalid_1's auc: 0.773618\n",
            "[400]\ttraining's binary_logloss: 0.223961\ttraining's auc: 0.826403\tvalid_1's binary_logloss: 0.240558\tvalid_1's auc: 0.776205\n",
            "[500]\ttraining's binary_logloss: 0.219667\ttraining's auc: 0.837626\tvalid_1's binary_logloss: 0.240092\tvalid_1's auc: 0.777397\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.219667\ttraining's auc: 0.837626\tvalid_1's binary_logloss: 0.240092\tvalid_1's auc: 0.777397\n",
            "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7774  \u001b[0m | \u001b[0m 0.6638  \u001b[0m | \u001b[0m 478.1   \u001b[0m | \u001b[0m 14.14   \u001b[0m | \u001b[0m 19.42   \u001b[0m | \u001b[0m 47.59   \u001b[0m | \u001b[0m 62.23   \u001b[0m | \u001b[0m 7.326   \u001b[0m | \u001b[0m 5.152   \u001b[0m | \u001b[0m 0.8538  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.242371\ttraining's auc: 0.781128\tvalid_1's binary_logloss: 0.247334\tvalid_1's auc: 0.7596\n",
            "[200]\ttraining's binary_logloss: 0.232679\ttraining's auc: 0.803663\tvalid_1's binary_logloss: 0.242723\tvalid_1's auc: 0.769873\n",
            "[300]\ttraining's binary_logloss: 0.226208\ttraining's auc: 0.820325\tvalid_1's binary_logloss: 0.241241\tvalid_1's auc: 0.773856\n",
            "[400]\ttraining's binary_logloss: 0.220801\ttraining's auc: 0.834453\tvalid_1's binary_logloss: 0.240458\tvalid_1's auc: 0.776126\n",
            "[500]\ttraining's binary_logloss: 0.216217\ttraining's auc: 0.846246\tvalid_1's binary_logloss: 0.240081\tvalid_1's auc: 0.777123\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.216217\ttraining's auc: 0.846246\tvalid_1's binary_logloss: 0.240081\tvalid_1's auc: 0.777123\n",
            "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7771  \u001b[0m | \u001b[0m 0.7899  \u001b[0m | \u001b[0m 451.0   \u001b[0m | \u001b[0m 14.17   \u001b[0m | \u001b[0m 16.47   \u001b[0m | \u001b[0m 48.3    \u001b[0m | \u001b[0m 62.66   \u001b[0m | \u001b[0m 0.8003  \u001b[0m | \u001b[0m 5.522   \u001b[0m | \u001b[0m 0.5739  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.243874\ttraining's auc: 0.778882\tvalid_1's binary_logloss: 0.248008\tvalid_1's auc: 0.759313\n",
            "[200]\ttraining's binary_logloss: 0.23524\ttraining's auc: 0.798016\tvalid_1's binary_logloss: 0.243316\tvalid_1's auc: 0.768777\n",
            "[300]\ttraining's binary_logloss: 0.230093\ttraining's auc: 0.811013\tvalid_1's binary_logloss: 0.241679\tvalid_1's auc: 0.773045\n",
            "[400]\ttraining's binary_logloss: 0.226176\ttraining's auc: 0.820855\tvalid_1's binary_logloss: 0.240876\tvalid_1's auc: 0.775129\n",
            "[500]\ttraining's binary_logloss: 0.222776\ttraining's auc: 0.829652\tvalid_1's binary_logloss: 0.240353\tvalid_1's auc: 0.776519\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.222776\ttraining's auc: 0.829652\tvalid_1's binary_logloss: 0.240353\tvalid_1's auc: 0.776519\n",
            "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.6147  \u001b[0m | \u001b[0m 485.7   \u001b[0m | \u001b[0m 7.26    \u001b[0m | \u001b[0m 19.26   \u001b[0m | \u001b[0m 5.714   \u001b[0m | \u001b[0m 60.35   \u001b[0m | \u001b[0m 2.702   \u001b[0m | \u001b[0m 9.9     \u001b[0m | \u001b[0m 0.6904  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.24498\ttraining's auc: 0.77289\tvalid_1's binary_logloss: 0.248164\tvalid_1's auc: 0.757677\n",
            "[200]\ttraining's binary_logloss: 0.236659\ttraining's auc: 0.792195\tvalid_1's binary_logloss: 0.2433\tvalid_1's auc: 0.768396\n",
            "[300]\ttraining's binary_logloss: 0.231583\ttraining's auc: 0.805419\tvalid_1's binary_logloss: 0.241604\tvalid_1's auc: 0.772935\n",
            "[400]\ttraining's binary_logloss: 0.22748\ttraining's auc: 0.816337\tvalid_1's binary_logloss: 0.240637\tvalid_1's auc: 0.775689\n",
            "[500]\ttraining's binary_logloss: 0.224103\ttraining's auc: 0.825461\tvalid_1's binary_logloss: 0.240223\tvalid_1's auc: 0.776814\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.224103\ttraining's auc: 0.825461\tvalid_1's binary_logloss: 0.240223\tvalid_1's auc: 0.776814\n",
            "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7768  \u001b[0m | \u001b[0m 0.7049  \u001b[0m | \u001b[0m 484.8   \u001b[0m | \u001b[0m 10.56   \u001b[0m | \u001b[0m 13.1    \u001b[0m | \u001b[0m 48.91   \u001b[0m | \u001b[0m 43.8    \u001b[0m | \u001b[0m 0.5117  \u001b[0m | \u001b[0m 9.967   \u001b[0m | \u001b[0m 0.7057  \u001b[0m |\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[100]\ttraining's binary_logloss: 0.245158\ttraining's auc: 0.770998\tvalid_1's binary_logloss: 0.248275\tvalid_1's auc: 0.757085\n",
            "[200]\ttraining's binary_logloss: 0.23683\ttraining's auc: 0.791679\tvalid_1's binary_logloss: 0.243534\tvalid_1's auc: 0.767821\n",
            "[300]\ttraining's binary_logloss: 0.231488\ttraining's auc: 0.806403\tvalid_1's binary_logloss: 0.241821\tvalid_1's auc: 0.772479\n",
            "[400]\ttraining's binary_logloss: 0.227132\ttraining's auc: 0.818757\tvalid_1's binary_logloss: 0.240942\tvalid_1's auc: 0.77485\n",
            "[500]\ttraining's binary_logloss: 0.223328\ttraining's auc: 0.830021\tvalid_1's binary_logloss: 0.2406\tvalid_1's auc: 0.77589\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[500]\ttraining's binary_logloss: 0.223328\ttraining's auc: 0.830021\tvalid_1's binary_logloss: 0.2406\tvalid_1's auc: 0.77589\n",
            "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7759  \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 499.1   \u001b[0m | \u001b[0m 9.791   \u001b[0m | \u001b[0m 12.04   \u001b[0m | \u001b[0m 1.209   \u001b[0m | \u001b[0m 37.5    \u001b[0m | \u001b[0m 1.511   \u001b[0m | \u001b[0m 0.2041  \u001b[0m | \u001b[0m 0.5108  \u001b[0m |\n",
            "=====================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# BayesianOptimization객체를 수행할 함수와 search할 parameter 범위를 설정하여 생성.\n",
        "lgbBO = BayesianOptimization(lgb_roc_eval,bayesian_params , random_state=0)\n",
        "# 함수 반환값이 최대가 되는 입력값 유추를 위한 iteration 수행.\n",
        "lgbBO.maximize(init_points=5, n_iter=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L3qCmiXvR5a"
      },
      "source": [
        "##### Iteration 수행 결과 출력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DinJ-PaxvR5c"
      },
      "outputs": [],
      "source": [
        "# BayesianOptimization객체의 res는 iteration 수행 시마다 모든 함수 반환결과와 그때의 파라미터 결과값을 가지고 있음.\n",
        "lgbBO.res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pF714uFvR5l"
      },
      "source": [
        "##### Iteration 결과 Dictionary에서 최대 target값을 가지는 index 추출하고 그때의 parameter 값을 추출.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR-_KsyivR5o"
      },
      "outputs": [],
      "source": [
        "# dictionary에 있는 target값을 모두 추출\n",
        "target_list = []\n",
        "for result in lgbBO.res:\n",
        "    target = result['target']\n",
        "    target_list.append(target)\n",
        "print(target_list)\n",
        "# 가장 큰 target 값을 가지는 순번(index)를 추출\n",
        "print('maximum target index:', np.argmax(np.array(target_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZLxoImyvR5x"
      },
      "outputs": [],
      "source": [
        "# 가장 큰 target값을 가지는 index값을 기준으로 res에서 해당 parameter 추출.\n",
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ0EHnuIvR53"
      },
      "source": [
        "##### 최적화된 하이퍼 파라미터를 기반으로 재 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32l2G2bZvR54"
      },
      "outputs": [],
      "source": [
        "def train_apps_all(apps_all_train):\n",
        "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=1000,\n",
        "                learning_rate=0.02,\n",
        "                max_depth = 13,\n",
        "                num_leaves=57,\n",
        "                colsample_bytree=0.638,\n",
        "                subsample=0.682,\n",
        "                max_bin=435,\n",
        "                reg_alpha=0.936,\n",
        "                reg_lambda=4.533,\n",
        "                min_child_weight=25,\n",
        "                min_child_samples=166,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100,\n",
        "                early_stopping_rounds= 100)\n",
        "\n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxqV8KpFvR5_"
      },
      "outputs": [],
      "source": [
        "apps_all = get_apps_all_with_prev_agg(apps, prev)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "clf = train_apps_all(apps_all_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQrAcQ1QvR6I"
      },
      "outputs": [],
      "source": [
        "preds = clf.predict_proba(apps_all_test.drop('SK_ID_CURR', axis=1))[:, 1 ]\n",
        "apps_all_test['TARGET'] = preds\n",
        "# SK_ID_CURR과 TARGET 값만 csv 형태로 생성. 코랩 버전은 구글 드라이브 절대 경로로 입력\n",
        "default_dir = \"/content/gdrive/My Drive\"\n",
        "app_test[['SK_ID_CURR', 'TARGET']].to_csv(os.path.join(default_dir,'prev_baseline_tuning_01.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l01RNW9nvR6y"
      },
      "source": [
        "##### cross validation 으로 hyper parameter 재 tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiIYNGFI0Tj4"
      },
      "outputs": [],
      "source": [
        "bayesian_params = {\n",
        "    'max_depth': (6, 16),\n",
        "    'num_leaves': (24, 64),\n",
        "    'min_data_in_leaf': (10, 200), # min_child_samples\n",
        "    'min_child_weight':(1, 50),\n",
        "    'bagging_fraction':(0.5, 1.0), # subsample\n",
        "    'feature_fraction': (0.5, 1.0), # colsample_bytree\n",
        "    'max_bin':(10, 500),\n",
        "    'lambda_l2':(0.001, 10), # reg_lambda\n",
        "    'lambda_l1': (0.01, 50) # reg_alpha\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKiN_Tdl0Tj4"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "train_data = lgb.Dataset(data=ftr_app, label=target_app, free_raw_data=False)\n",
        "def lgb_roc_eval_cv(max_depth, num_leaves, min_data_in_leaf, min_child_weight, bagging_fraction,\n",
        "                 feature_fraction,  max_bin, lambda_l2, lambda_l1):\n",
        "    params = {\n",
        "        \"num_iterations\":500, \"learning_rate\":0.02,\n",
        "        'early_stopping_rounds':100, 'metric':'auc',\n",
        "        'max_depth': int(round(max_depth)), #  호출 시 실수형 값이 들어오므로 실수형 하이퍼 파라미터는 정수형으로 변경\n",
        "        'num_leaves': int(round(num_leaves)),\n",
        "        'min_data_in_leaf': int(round(min_data_in_leaf)),\n",
        "        'min_child_weight': int(round(min_child_weight)),\n",
        "        'bagging_fraction': max(min(bagging_fraction, 1), 0),\n",
        "        'feature_fraction': max(min(feature_fraction, 1), 0),\n",
        "        'max_bin':  max(int(round(max_bin)),10),\n",
        "        'lambda_l2': max(lambda_l2,0),\n",
        "        'lambda_l1': max(lambda_l1, 0)\n",
        "    }\n",
        "    # 파이썬 lightgbm의 cv 메소드를 사용.\n",
        "\n",
        "    cv_result = lgb.cv(params, train_data, nfold=3, seed=0,  verbose_eval =100,  early_stopping_rounds=50, metrics=['auc'])\n",
        "    return max(cv_result['auc-mean'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a4oJjog0Tj5"
      },
      "outputs": [],
      "source": [
        "max_dict = lgbBO.res[np.argmax(np.array(target_list))]\n",
        "print(max_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD86PsvH0Tj5"
      },
      "outputs": [],
      "source": [
        "def train_apps_all(apps_all_train):\n",
        "    ftr_app = apps_all_train.drop(['SK_ID_CURR', 'TARGET'], axis=1)\n",
        "    target_app = apps_all_train['TARGET']\n",
        "\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(ftr_app, target_app, test_size=0.3, random_state=2020)\n",
        "    print('train shape:', train_x.shape, 'valid shape:', valid_x.shape)\n",
        "    clf = LGBMClassifier(\n",
        "                nthread=4,\n",
        "                n_estimators=1000,\n",
        "                learning_rate=0.02,\n",
        "                max_depth = 10,\n",
        "                num_leaves=60,\n",
        "                colsample_bytree=0.511,\n",
        "                subsample=0.785,\n",
        "                max_bin=208,\n",
        "                reg_alpha=7.009,\n",
        "                reg_lambda=6.579,\n",
        "                min_child_weight=40,\n",
        "                min_child_samples=91,\n",
        "                silent=-1,\n",
        "                verbose=-1,\n",
        "                )\n",
        "\n",
        "    clf.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y)], eval_metric= 'auc', verbose= 100,\n",
        "                early_stopping_rounds= 100)\n",
        "\n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OTFwAiw0Tj5"
      },
      "outputs": [],
      "source": [
        "apps_all = get_apps_all_with_prev_agg(apps, prev)\n",
        "apps_all = get_apps_all_encoded(apps_all)\n",
        "apps_all_train, apps_all_test = get_apps_all_train_test(apps_all)\n",
        "clf = train_apps_all(apps_all_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AHWf3XD0Tj5"
      },
      "outputs": [],
      "source": [
        "preds = clf.predict_proba(apps_all_test.drop('SK_ID_CURR', axis=1))[:, 1 ]\n",
        "apps_all_test['TARGET'] = preds\n",
        "# SK_ID_CURR과 TARGET 값만 csv 형태로 생성. 코랩 버전은 구글 드라이브 절대 경로로 입력\n",
        "default_dir = \"/content/gdrive/My Drive\"\n",
        "app_test[['SK_ID_CURR', 'TARGET']].to_csv(os.path.join(default_dir,'prev_baseline_tuning_02.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23BsBq0x0Tj5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}